{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a761440-99ee-4bc1-9860-d6e4e79c8906",
   "metadata": {},
   "source": [
    "# Pwskills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc30b85-6bd9-46bd-8627-538d017590d6",
   "metadata": {},
   "source": [
    "## Data Science Master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814a0e1-81fa-4471-88a3-94c55963f725",
   "metadata": {},
   "source": [
    "### KNN-1 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9814a575-cbc1-4b3b-93a1-939798640e8d",
   "metadata": {},
   "source": [
    "Q1. Write a Python code to implement the KNN classifier algorithm on load_iris dataset in\n",
    "sklearn.datasets.\n",
    "\n",
    "ChatGPT\n",
    "Certainly! Here's an example Python code that implements the K-Nearest Neighbors (KNN) classifier algorithm on the load_iris dataset from sklearn.datasets:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "In this code, we first import the necessary libraries: load_iris from sklearn.datasets to load the Iris dataset, train_test_split from sklearn.model_selection to split the dataset into training and testing sets, KNeighborsClassifier from sklearn.neighbors to create the KNN classifier, and accuracy_score from sklearn.metrics to calculate the accuracy of the classifier.\n",
    "\n",
    "Next, we load the Iris dataset using load_iris() and split it into training and testing sets using train_test_split(). We set aside 20% of the data for testing and use a random state of 42 for reproducibility.\n",
    "\n",
    "Then, we create a KNN classifier with n_neighbors=3, meaning it will consider the three nearest neighbors for classification.\n",
    "\n",
    "After that, we train the KNN classifier using the training data by calling fit(X_train, y_train).\n",
    "\n",
    "Next, we make predictions on the test set using predict(X_test).\n",
    "\n",
    "Finally, we calculate the accuracy of the classifier by comparing the predicted labels (y_pred) with the true labels (y_test) using accuracy_score(), and print the accuracy.\n",
    "\n",
    "Note that the code assumes you have scikit-learn installed (pip install scikit-learn).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User\n",
    "Q2. Write a Python code to implement the KNN regressor algorithm on load_boston dataset in\n",
    "sklearn.datasets.\n",
    "ChatGPT\n",
    "Certainly! Here's an example Python code that implements the K-Nearest Neighbors (KNN) regressor algorithm on the load_boston dataset from sklearn.datasets:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN regressor with k=3\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Train the regressor\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "In this code, we import the necessary libraries: load_boston from sklearn.datasets to load the Boston Housing dataset, train_test_split from sklearn.model_selection to split the dataset into training and testing sets, KNeighborsRegressor from sklearn.neighbors to create the KNN regressor, and mean_squared_error from sklearn.metrics to calculate the mean squared error.\n",
    "\n",
    "Next, we load the Boston Housing dataset using load_boston() and split it into training and testing sets using train_test_split(). We set aside 20% of the data for testing and use a random state of 42 for reproducibility.\n",
    "\n",
    "Then, we create a KNN regressor with n_neighbors=3,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User\n",
    "Q3. Write a Python code snippet to find the optimal value of K for the KNN classifier algorithm using\n",
    "cross-validation on load_iris dataset in sklearn.datasets.\n",
    "ChatGPT\n",
    "\n",
    "1 / 2\n",
    "\n",
    "Certainly! Here's a Python code snippet that uses cross-validation to find the optimal value of K for the KNN classifier algorithm on the load_iris dataset from sklearn.datasets:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Initialize a list to store mean accuracy scores for different values of K\n",
    "mean_scores = []\n",
    "\n",
    "# Try different values of K from 1 to 10\n",
    "k_values = range(1, 11)\n",
    "\n",
    "# Perform cross-validation for each K value\n",
    "for k in k_values:\n",
    "    # Create a KNN classifier with k neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Perform cross-validation and calculate mean accuracy\n",
    "    scores = cross_val_score(knn, iris.data, iris.target, cv=5)\n",
    "    mean_scores.append(scores.mean())\n",
    "\n",
    "# Find the optimal K with the highest mean accuracy\n",
    "optimal_k = k_values[mean_scores.index(max(mean_scores))]\n",
    "\n",
    "print(\"Optimal K:\", optimal_k)\n",
    "In this code, we first import the necessary libraries: load_iris from sklearn.datasets to load the Iris dataset, cross_val_score from sklearn.model_selection to perform cross-validation, and KNeighborsClassifier from sklearn.neighbors to create the KNN classifier.\n",
    "\n",
    "Next, we load the Iris dataset using load_iris().\n",
    "\n",
    "Then, we initialize an empty list mean_scores to store the mean accuracy scores for different values of K.\n",
    "\n",
    "We iterate over the values of K from 1 to 10 using range(1, 11). For each value of K, we create a KNN classifier with n_neighbors=k.\n",
    "\n",
    "Inside the loop, we perform cross-validation using cross_val_score(). We pass the KNN classifier, the Iris dataset features (iris.data), and target (iris.target), and specify cv=5 to perform 5-fold cross-validation (5 folds).\n",
    "\n",
    "We calculate the mean accuracy score for each K value by calling .mean() on the returned array of cross-validation scores, and append it to the mean_scores list.\n",
    "\n",
    "After the loop, we find the optimal K value by using the max() function on the mean_scores list to get the highest mean accuracy score, and then use mean_scores.index(max(mean_scores)) to find the index of that score. Finally, we retrieve the corresponding K value from the k_values list.\n",
    "\n",
    "Finally, we print the optimal K value.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User\n",
    "\n",
    "2 / 2\n",
    "\n",
    "Q4. Implement the KNN regressor algorithm with feature scaling on load_boston dataset in\n",
    "sklearn.datasets.\n",
    "ChatGPT\n",
    "Sure! Here's an example Python code that implements the K-Nearest Neighbors (KNN) regressor algorithm with feature scaling on the load_boston dataset from sklearn.datasets:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the dataset\n",
    "boston = load_boston()\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature scaling on the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN regressor with k=3\n",
    "knn = KNeighborsRegressor(n_neighbors=3)\n",
    "\n",
    "# Train the regressor\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the scaled test set\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "In this code, we import the necessary libraries: load_boston from sklearn.datasets to load the Boston Housing dataset, train_test_split from sklearn.model_selection to split the dataset into training and testing sets, KNeighborsRegressor from sklearn.neighbors to create the KNN regressor, StandardScaler from sklearn.preprocessing to perform feature scaling, and mean_squared_error from sklearn.metrics to calculate the mean squared error.\n",
    "\n",
    "Next, we load the Boston Housing dataset using load_boston() and split it into training and testing sets using train_test_split(). We set aside 20% of the data for testing and use a random state of 42 for reproducibility.\n",
    "\n",
    "Then, we create an instance of StandardScaler and use it to perform feature scaling on the features. We call fit_transform() on the training set (X_train) to fit the scaler and scale the training features, and then call transform() on the test set (X_test) to scale the test features using the learned scaling parameters.\n",
    "\n",
    "After that, we create a KNN regressor with n_neighbors=3, meaning it will consider the three nearest neighbors for regression.\n",
    "\n",
    "Next, we train the KNN regressor using the scaled training data (X_train_scaled) and the corresponding target labels (y_train).\n",
    "\n",
    "We then make predictions on the scaled test set (X_test_scaled) using predict().\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User\n",
    "Q6. Implement a function to standardise the features before applying KNN classifier.\n",
    "ChatGPT\n",
    "Certainly! Here's an example of a Python function that performs feature standardization before applying the KNN classifier algorithm:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def knn_classifier_with_standardization(X_train, y_train, X_test, n_neighbors):\n",
    "    # Perform feature standardization\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Create a KNN classifier with the specified number of neighbors\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    \n",
    "    # Train the classifier\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on the scaled test set\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    \n",
    "    # Return the predicted labels\n",
    "    return y_pred\n",
    "This function takes four parameters:\n",
    "\n",
    "X_train: The training set features.\n",
    "y_train: The corresponding training set labels.\n",
    "X_test: The test set features.\n",
    "n_neighbors: The number of neighbors to consider in the KNN classifier.\n",
    "Inside the function, we create an instance of StandardScaler to perform feature standardization. We call fit_transform() on the training set features (X_train) to fit the scaler and transform the training features. Then, we call transform() on the test set features (X_test) to transform them using the learned scaling parameters.\n",
    "\n",
    "Next, we create a KNN classifier with the specified number of neighbors using KNeighborsClassifier(n_neighbors=n_neighbors).\n",
    "\n",
    "We then train the classifier by calling fit() with the scaled training features (X_train_scaled) and the corresponding training labels (y_train).\n",
    "\n",
    "After that, we make predictions on the scaled test set features (X_test_scaled) using predict().\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "User\n",
    "Q7. Write a Python function to calculate the euclidean distance between two points.\n",
    "ChatGPT\n",
    "Certainly! Here's a Python function that calculates the Euclidean distance between two points in a n-dimensional space:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    # Check if the dimensions of the two points are the same\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"The dimensions of the points are not the same.\")\n",
    "    \n",
    "    # Calculate the sum of squared differences for each dimension\n",
    "    squared_diff = sum((p1 - p2) ** 2 for p1, p2 in zip(point1, point2))\n",
    "    \n",
    "    # Calculate the square root of the sum of squared differences\n",
    "    distance = math.sqrt(squared_diff)\n",
    "    \n",
    "    return distance\n",
    "The euclidean_distance function takes two parameters:\n",
    "\n",
    "point1: A list or tuple representing the coordinates of the first point.\n",
    "point2: A list or tuple representing the coordinates of the second point.\n",
    "Inside the function, we first check if the dimensions of the two points are the same. If they are not the same, we raise a ValueError indicating that the dimensions are not compatible for distance calculation.\n",
    "\n",
    "Next, we calculate the sum of squared differences for each dimension by using a generator expression and the zip function to iterate over the corresponding coordinates of point1 and point2.\n",
    "\n",
    "Then, we calculate the square root of the sum of squared differences using the math.sqrt function.\n",
    "\n",
    "Finally, we return the calculated Euclidean distance.\n",
    "\n",
    "Here's an example usage of the function:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "point1 = (1, 2, 3)\n",
    "point2 = (4, 5, 6)\n",
    "distance = euclidean_distance(point1, point2)\n",
    "print(\"Euclidean distance:\", distance)\n",
    "Output:\n",
    "\n",
    "yaml\n",
    "Copy code\n",
    "Euclidean distance: 5.196152422706632\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q8. Write a Python function to calculate the manhattan distance between two points.\n",
    "\n",
    "Certainly! Here's a Python function that calculates the Manhattan distance between two points in a n-dimensional space:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "def manhattan_distance(point1, point2):\n",
    "    # Check if the dimensions of the two points are the same\n",
    "    if len(point1) != len(point2):\n",
    "        raise ValueError(\"The dimensions of the points are not the same.\")\n",
    "\n",
    "    # Calculate the sum of absolute differences for each dimension\n",
    "    abs_diff = sum(abs(p1 - p2) for p1, p2 in zip(point1, point2))\n",
    "\n",
    "    return abs_diff\n",
    "The manhattan_distance function takes two parameters:\n",
    "\n",
    "point1: A list or tuple representing the coordinates of the first point.\n",
    "point2: A list or tuple representing the coordinates of the second point.\n",
    "Inside the function, we first check if the dimensions of the two points are the same. If they are not the same, we raise a ValueError indicating that the dimensions are not compatible for distance calculation.\n",
    "\n",
    "Next, we calculate the sum of absolute differences for each dimension by using a generator expression and the zip function to iterate over the corresponding coordinates of point1 and point2.\n",
    "\n",
    "Finally, we return the calculated Manhattan distance.\n",
    "\n",
    "Here's an example usage of the function:\n",
    "\n",
    "python\n",
    "Copy code\n",
    "point1 = (1, 2, 3)\n",
    "point2 = (4, 5, 6)\n",
    "distance = manhattan_distance(point1, point2)\n",
    "print(\"Manhattan distance:\", distance)\n",
    "Output:\n",
    "\n",
    "yaml\n",
    "Copy code\n",
    "Manhattan distance: 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
