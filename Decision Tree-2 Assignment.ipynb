{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aa539d8-b067-4d8f-b63f-ea7dfdd5f74d",
   "metadata": {},
   "source": [
    "# Pwskills"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bfc1d6-83a9-4682-9368-c6ce5ce05fd8",
   "metadata": {},
   "source": [
    "## Data Science Master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce81a0-0a00-4d5c-8479-7af6e40680fd",
   "metadata": {},
   "source": [
    "### Decision Tree-2 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec35e97-c82f-455f-bac7-147476606b9f",
   "metadata": {},
   "source": [
    "You are a data scientist working for a healthcare company, and you have been tasked with creating a\n",
    "decision tree to help identify patients with diabetes based on a set of clinical variables. You have been\n",
    "given a dataset (diabetes.csv) with the following variables:\n",
    "1. Pregnancies: Number of times pregnant (integer)\n",
    "2. Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test (integer)\n",
    "3. BloodPressure: Diastolic blood pressure (mm Hg) (integer)\n",
    "4. SkinThickness: Triceps skin fold thickness (mm) (integer)\n",
    "5. Insulin: 2-Hour serum insulin (mu U/ml) (integer)\n",
    "6. BMI: Body mass index (weight in kg/(height in m)^2) (float)\n",
    "7. DiabetesPedigreeFunction: Diabetes pedigree function (a function which scores likelihood of diabetes\n",
    "based on family history) (float)\n",
    "8. Age: Age in years (integer)\n",
    "9. Outcome: Class variable (0 if non-diabetic, 1 if diabetic) (integer)\n",
    "\n",
    "\n",
    "To create a decision tree for identifying patients with diabetes based on the given dataset, you can follow these steps:\n",
    "\n",
    "Step 1: Import the necessary libraries\n",
    "You'll need to import the required libraries for data manipulation and building the decision tree. The common libraries used in this scenario are pandas and scikit-learn.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "Step 2: Load the dataset\n",
    "Load the dataset from the provided CSV file using the pandas library.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "Step 3: Prepare the data\n",
    "Separate the features (independent variables) and the target variable (Outcome) from the dataset.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "features = data.drop('Outcome', axis=1)\n",
    "target = data['Outcome']\n",
    "Step 4: Split the data into training and testing sets\n",
    "Split the dataset into a training set and a testing set. This will allow you to train the decision tree on a portion of the data and evaluate its performance on unseen data.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "Step 5: Build the decision tree\n",
    "Create an instance of the DecisionTreeClassifier and fit it to the training data.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "Step 6: Make predictions\n",
    "Use the trained decision tree to make predictions on the testing set.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "y_pred = classifier.predict(X_test)\n",
    "Step 7: Evaluate the model\n",
    "Assess the performance of the decision tree model by comparing the predicted outcomes with the actual outcomes from the testing set.\n",
    "\n",
    "python\n",
    "Copy code\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "This will print the accuracy of the decision tree model in identifying patients with diabetes.\n",
    "\n",
    "You can further visualize the decision tree using graphviz or other visualization libraries to gain insights into the decision-making process.\n",
    "\n",
    "Note: It's important to preprocess the data if it contains missing values or outliers. Additionally, feature scaling may be required for some algorithms, but decision trees are not sensitive to feature scaling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Q1. Import the dataset and examine the variables. Use descriptive statistics and visualizations to\n",
    "understand the distribution and relationships between the variables.\n",
    "Q2. Preprocess the data by cleaning missing values, removing outliers, and transforming categorical\n",
    "variables into dummy variables if necessary.\n",
    "Q3. Split the dataset into a training set and a test set. Use a random seed to ensure reproducibility.\n",
    "Q4. Use a decision tree algorithm, such as ID3 or C4.5, to train a decision tree model on the training set. Use\n",
    "cross-validation to optimize the hyperparameters and avoid overfitting.\n",
    "Q5. Evaluate the performance of the decision tree model on the test set using metrics such as accuracy,\n",
    "precision, recall, and F1 score. Use confusion matrices and ROC curves to visualize the results.\n",
    "Q6. Interpret the decision tree by examining the splits, branches, and leaves. Identify the most important\n",
    "variables and their thresholds. Use domain knowledge and common sense to explain the patterns and\n",
    "trends.\n",
    "Q7. Validate the decision tree model by applying it to new data or testing its robustness to changes in the\n",
    "dataset or the environment. Use sensitivity analysis and scenario testing to explore the uncertainty and\n",
    "risks.\n",
    "Hereâ€™s the dataset link:\n",
    "\n",
    "To accomplish the tasks you mentioned, I'll guide you through each step:\n",
    "\n",
    "Step 1: Import the necessary libraries and load the dataset\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "Step 2: Examine the variables and understand their distribution and relationships\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Get descriptive statistics of the dataset\n",
    "print(data.describe())\n",
    "\n",
    "# Visualize the distribution of variables using histograms\n",
    "data.hist(figsize=(10, 8))\n",
    "plt.show()\n",
    "\n",
    "# Visualize the relationships between variables using a correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "Step 3: Preprocess the data\n",
    "\n",
    "python\n",
    "Copy code\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Remove outliers (assuming outliers are present)\n",
    "# Implement appropriate outlier detection and removal techniques based on the distribution of variables\n",
    "\n",
    "# Transform categorical variables into dummy variables if any exist\n",
    "# If there are categorical variables, you can use the pandas get_dummies() function to create dummy variables\n",
    "# Example: data = pd.get_dummies(data, columns=['CategoricalVariable'])\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "features = data.drop('Outcome', axis=1)\n",
    "target = data['Outcome']\n",
    "Step 4: Split the dataset into a training set and a test set\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "Step 5: Train the decision tree model and optimize hyperparameters\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid for hyperparameter optimization\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Create an instance of the DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Perform grid search using cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and retrain the model\n",
    "best_params = grid_search.best_params_\n",
    "classifier = DecisionTreeClassifier(**best_params)\n",
    "classifier.fit(X_train, y_train)\n",
    "Step 6: Evaluate the performance of the decision tree model\n",
    "\n",
    "python\n",
    "Copy code\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Plot the ROC curve\n",
    "y_pred_prob = classifier.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "Step 7: Interpret and validate the decision tree model\n",
    "\n",
    "Interpret the decision tree structure by visualizing it using graphviz or other libraries.\n",
    "Identify the most important variables by examining the feature importances provided by the decision tree model.\n",
    "Validate the model's performance using cross-validation, applying it to new data, or conducting scenario testing.\n",
    "Please note that the code provided is a general outline, and you may need to adapt it based on your specific requirements and the characteristics of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fb52e-1a1d-44ab-b54a-9492541ad9e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
